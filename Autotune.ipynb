{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Tnob5XYRxONE1gAy7l4LDmo8iK9pQeCP",
      "authorship_tag": "ABX9TyPL2lZ4npol/8Z3JNnsoFI9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olaviinha/SloppyButchery/blob/main/Autotune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font face=\"Trebuchet MS\" size=\"6\">Autotune <font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font color=\"#999\" size=\"4\">Sloppy Butchery</font><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><a href=\"https://github.com/olaviinha/SloppyButchery\" target=\"_blank\"><font color=\"#999\" size=\"4\">Github</font></a>\n",
        "\n",
        "#### Autotune audio file or a directory of audio files to:\n",
        "- scale\n",
        "- nearest note\n",
        "- another audio file\n",
        "- [Chords Guru Turbo 100a Deluxe](https://ki.gy/cv) chord progression\n",
        "\n",
        "#### Tips:\n",
        "- All directory/file paths should be relative to your Google Drive root (e.g. `audio/voice/vocals.wav` if you have a directory called _audio_ in your drive, etc.)\n",
        "- Try 44.1 kHz WAV if you experience problems with other formats."
      ],
      "metadata": {
        "id": "GBgr33OisX3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Setup\n",
        "#@markdown This cell needs to be run only once. It will mount your Google Drive and setup prerequisites.<br>\n",
        "#@markdown <small>This notebook requires moutning Google Drive.</small>\n",
        "\n",
        "force_setup = False\n",
        "repositories = []\n",
        "pip_packages = 'librosa soundfile scipy psola mido'\n",
        "apt_packages = ''\n",
        "mount_drive = True #@ param {type:\"boolean\"}\n",
        "skip_setup = False #@ param {type:\"boolean\"}\n",
        "\n",
        "# Download the repo from Github\n",
        "import os\n",
        "from google.colab import output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%cd /content/\n",
        "\n",
        "# inhagcutils\n",
        "if not os.path.isfile('/content/inhagcutils.ipynb') and force_setup == False:\n",
        "  !pip -q install import-ipynb {pip_packages}\n",
        "  if apt_packages != '':\n",
        "    !apt-get update && apt-get install {apt_packages}\n",
        "  !curl -s -O https://raw.githubusercontent.com/olaviinha/inhagcutils/master/inhagcutils.ipynb\n",
        "import import_ipynb\n",
        "from inhagcutils import *\n",
        "\n",
        "# Mount Drive\n",
        "if mount_drive == True:\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    drive_root = '/content/drive/My Drive'\n",
        "  if not os.path.isdir('/content/mydrive'):\n",
        "    os.symlink('/content/drive/My Drive', '/content/mydrive')\n",
        "    drive_root = '/content/mydrive/'\n",
        "  drive_root_set = True\n",
        "else:\n",
        "  create_dirs(['/content/faux_drive'])\n",
        "  drive_root = '/content/faux_drive/'\n",
        "\n",
        "if len(repositories) > 0 and skip_setup == False:\n",
        "  for repo in repositories:\n",
        "    %cd /content/\n",
        "    install_dir = fix_path('/content/'+path_leaf(repo).replace('.git', ''))\n",
        "    repo = repo if '.git' in repo else repo+'.git'\n",
        "    !git clone {repo}\n",
        "    if os.path.isfile(install_dir+'setup.py') or os.path.isfile(install_dir+'setup.cfg'):\n",
        "      !pip install -e ./{install_dir}\n",
        "    if os.path.isfile(install_dir+'requirements.txt'):\n",
        "      !pip install -r {install_dir}/requirements.txt\n",
        "\n",
        "if len(repositories) == 1:\n",
        "  %cd {install_dir}\n",
        "\n",
        "dir_tmp = '/content/tmp/'\n",
        "create_dirs([dir_tmp])\n",
        "\n",
        "import time, sys\n",
        "from datetime import timedelta\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# og autotune.py\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path\n",
        "import argparse\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import soundfile as sf\n",
        "import scipy.signal as sig\n",
        "import psola\n",
        "\n",
        "\n",
        "SEMITONES_IN_OCTAVE = 12\n",
        "\n",
        "def degrees_from(scale: str):\n",
        "    \"\"\"Return the pitch classes (degrees) that correspond to the given scale\"\"\"\n",
        "    degrees = librosa.key_to_degrees(scale)\n",
        "    # To properly perform pitch rounding to the nearest degree from the scale, we need to repeat\n",
        "    # the first degree raised by an octave. Otherwise, pitches slightly lower than the base degree\n",
        "    # would be incorrectly assigned.\n",
        "    degrees = np.concatenate((degrees, [degrees[0] + SEMITONES_IN_OCTAVE]))\n",
        "    return degrees\n",
        "\n",
        "\n",
        "def closest_pitch(f0):\n",
        "    \"\"\"Round the given pitch values to the nearest MIDI note numbers\"\"\"\n",
        "    midi_note = np.around(librosa.hz_to_midi(f0))\n",
        "    # To preserve the nan values.\n",
        "    nan_indices = np.isnan(f0)\n",
        "    midi_note[nan_indices] = np.nan\n",
        "    # Convert back to Hz.\n",
        "    return librosa.midi_to_hz(midi_note)\n",
        "\n",
        "\n",
        "def closest_pitch_from_scale(f0, scale):\n",
        "    \"\"\"Return the pitch closest to f0 that belongs to the given scale\"\"\"\n",
        "    # Preserve nan.\n",
        "    if np.isnan(f0):\n",
        "        return np.nan\n",
        "    degrees = degrees_from(scale)\n",
        "    midi_note = librosa.hz_to_midi(f0)\n",
        "    # Subtract the multiplicities of 12 so that we have the real-valued pitch class of the\n",
        "    # input pitch.\n",
        "    degree = midi_note % SEMITONES_IN_OCTAVE\n",
        "    # Find the closest pitch class from the scale.\n",
        "    degree_id = np.argmin(np.abs(degrees - degree))\n",
        "    # Calculate the difference between the input pitch class and the desired pitch class.\n",
        "    degree_difference = degree - degrees[degree_id]\n",
        "    # Shift the input MIDI note number by the calculated difference.\n",
        "    midi_note -= degree_difference\n",
        "    # Convert to Hz.\n",
        "    return librosa.midi_to_hz(midi_note)\n",
        "\n",
        "\n",
        "def aclosest_pitch_from_scale(f0, scale):\n",
        "    \"\"\"Map each pitch in the f0 array to the closest pitch belonging to the given scale.\"\"\"\n",
        "    sanitized_pitch = np.zeros_like(f0)\n",
        "    for i in np.arange(f0.shape[0]):\n",
        "        sanitized_pitch[i] = closest_pitch_from_scale(f0[i], scale)\n",
        "    # Perform median filtering to additionally smooth the corrected pitch.\n",
        "    smoothed_sanitized_pitch = sig.medfilt(sanitized_pitch, kernel_size=11)\n",
        "    # Remove the additional NaN values after median filtering.\n",
        "    smoothed_sanitized_pitch[np.isnan(smoothed_sanitized_pitch)] = \\\n",
        "        sanitized_pitch[np.isnan(smoothed_sanitized_pitch)]\n",
        "    return smoothed_sanitized_pitch\n",
        "\n",
        "\n",
        "def autotune(audio, sr, correction_function, plot=False):\n",
        "    # Set some basis parameters.\n",
        "    frame_length = 2048\n",
        "    hop_length = frame_length // 4\n",
        "    fmin = librosa.note_to_hz('C2')\n",
        "    fmax = librosa.note_to_hz('C7')\n",
        "\n",
        "    # Pitch tracking using the PYIN algorithm.\n",
        "    f0, voiced_flag, voiced_probabilities = librosa.pyin(audio,\n",
        "                                                         frame_length=frame_length,\n",
        "                                                         hop_length=hop_length,\n",
        "                                                         sr=sr,\n",
        "                                                         fmin=fmin,\n",
        "                                                         fmax=fmax)\n",
        "\n",
        "    # Apply the chosen adjustment strategy to the pitch.\n",
        "    corrected_f0 = correction_function(f0)\n",
        "\n",
        "    if plot:\n",
        "        # Plot the spectrogram, overlaid with the original pitch trajectory and the adjusted\n",
        "        # pitch trajectory.\n",
        "        stft = librosa.stft(audio, n_fft=frame_length, hop_length=hop_length)\n",
        "        time_points = librosa.times_like(stft, sr=sr, hop_length=hop_length)\n",
        "        log_stft = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
        "        fig, ax = plt.subplots()\n",
        "        img = librosa.display.specshow(log_stft, x_axis='time', y_axis='log', ax=ax, sr=sr, hop_length=hop_length, fmin=fmin, fmax=fmax)\n",
        "        fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
        "        ax.plot(time_points, f0, label='original pitch', color='cyan', linewidth=2)\n",
        "        ax.plot(time_points, corrected_f0, label='corrected pitch', color='orange', linewidth=1)\n",
        "        ax.legend(loc='upper right')\n",
        "        plt.ylabel('Frequency [Hz]')\n",
        "        plt.xlabel('Time [M:SS]')\n",
        "        plt.savefig('pitch_correction.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "    # Pitch-shifting using the PSOLA algorithm.\n",
        "    return psola.vocode(audio, sample_rate=int(sr), target_pitch=corrected_f0, fmin=fmin, fmax=fmax)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Additions to autotune functions\n",
        "\n",
        "def closest_pitch_from_notes(f0, notes_string):\n",
        "    \"\"\"Return the pitch closest to f0 that belongs to the given scale\"\"\"\n",
        "    # Preserve nan.\n",
        "    if np.isnan(f0):\n",
        "        return np.nan\n",
        "    degrees = notes_string_to_degrees(notes_string)\n",
        "    midi_note = librosa.hz_to_midi(f0)\n",
        "    # Subtract the multiplicities of 12 so that we have the real-valued pitch class of the\n",
        "    # input pitch.\n",
        "    degree = midi_note % SEMITONES_IN_OCTAVE\n",
        "    # Find the closest pitch class from the scale.\n",
        "    degree_id = np.argmin(np.abs(degrees - degree))\n",
        "    # Calculate the difference between the input pitch class and the desired pitch class.\n",
        "    degree_difference = degree - degrees[degree_id]\n",
        "    # Shift the input MIDI note number by the calculated difference.\n",
        "    midi_note -= degree_difference\n",
        "    # Convert to Hz.\n",
        "    return librosa.midi_to_hz(midi_note)\n",
        "\n",
        "def aclosest_pitch_from_notes(f0, notes_string):\n",
        "    \"\"\"Map each pitch in the f0 array to the closest pitch belonging to the given scale.\"\"\"\n",
        "    sanitized_pitch = np.zeros_like(f0)\n",
        "    for i in np.arange(f0.shape[0]):\n",
        "        sanitized_pitch[i] = closest_pitch_from_notes(f0[i], notes_string)\n",
        "    # Perform median filtering to additionally smooth the corrected pitch.\n",
        "    smoothed_sanitized_pitch = sig.medfilt(sanitized_pitch, kernel_size=11)\n",
        "    # Remove the additional NaN values after median filtering.\n",
        "    smoothed_sanitized_pitch[np.isnan(smoothed_sanitized_pitch)] = \\\n",
        "        sanitized_pitch[np.isnan(smoothed_sanitized_pitch)]\n",
        "    return smoothed_sanitized_pitch\n",
        "\n",
        "def notes_string_to_degrees(notes):\n",
        "  og_notes = notes.split(',')\n",
        "  new_notes = [int(note)-int(og_notes[0]) for note in og_notes]\n",
        "  degrees = np.array(new_notes)\n",
        "  degrees = np.concatenate((degrees, [degrees[0] + SEMITONES_IN_OCTAVE]))\n",
        "  return degrees\n",
        "\n",
        "def wav2wav_autotune(audio, pitch_audio, sr, plot=False):\n",
        "    # Set some basis parameters.\n",
        "    frame_length = 2048\n",
        "    hop_length = frame_length // 4\n",
        "    fmin = librosa.note_to_hz('C2')\n",
        "    fmax = librosa.note_to_hz('C7')\n",
        "\n",
        "    # Pitch tracking using the PYIN algorithm.\n",
        "    f0, voiced_flag, voiced_probabilities = librosa.pyin(pitch_audio, frame_length=frame_length, hop_length=hop_length, sr=sr, fmin=fmin, fmax=fmax)\n",
        "\n",
        "    # Apply the chosen adjustment strategy to the pitch.\n",
        "    corrected_f0 = closest_pitch(f0)\n",
        "\n",
        "    if plot:\n",
        "        # Plot the spectrogram, overlaid with the original pitch trajectory and the adjusted\n",
        "        # pitch trajectory.\n",
        "        stft = librosa.stft(audio, n_fft=frame_length, hop_length=hop_length)\n",
        "        time_points = librosa.times_like(stft, sr=sr, hop_length=hop_length)\n",
        "        log_stft = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
        "        fig, ax = plt.subplots()\n",
        "        img = librosa.display.specshow(log_stft, x_axis='time', y_axis='log', ax=ax, sr=sr, hop_length=hop_length, fmin=fmin, fmax=fmax)\n",
        "        fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
        "        ax.plot(time_points, f0, label='original pitch', color='cyan', linewidth=2)\n",
        "        ax.plot(time_points, corrected_f0, label='corrected pitch', color='orange', linewidth=1)\n",
        "        ax.legend(loc='upper right')\n",
        "        plt.ylabel('Frequency [Hz]')\n",
        "        plt.xlabel('Time [M:SS]')\n",
        "        plt.savefig('pitch_correction.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "    # Pitch-shifting using the PSOLA algorithm.\n",
        "    return psola.vocode(audio, sample_rate=int(sr), target_pitch=corrected_f0, fmin=fmin, fmax=fmax)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Librosa audio functions\n",
        "\n",
        "def split_channels(audio_data):\n",
        "  return audio_data[0], audio_data[1]\n",
        "\n",
        "def merge_channels(left_data, right_data):\n",
        "  return np.array([left_data, right_data])\n",
        "\n",
        "def narrow_stereo(left_data, right_data, amount):\n",
        "  amount = amount/2\n",
        "  left = left_data * (1-amount) + right_data * amount\n",
        "  right = right_data * (1-amount) + left_data * amount\n",
        "  return np.array([left, right])\n",
        "\n",
        "def time_stretch_audio(audio, sr, to_length):\n",
        "  dur = librosa.get_duration(audio, sr=sr)\n",
        "  return np.array([librosa.effects.time_stretch(channel, dur/to_length) for channel in split_channels(audio)])\n",
        "\n",
        "# Slice audio signal\n",
        "# Returns slices as audio\n",
        "def slice_to_frames(audio_data, sr=44100, slice_duration=1, fade_in=0, fade_out=0, fx=[]):\n",
        "  a_duration = librosa.get_duration(audio_data, sr=sr)\n",
        "  clips = math.ceil(a_duration/slice_duration)\n",
        "  frames = []\n",
        "  for i in range(clips):\n",
        "    # if i > 0 and i < clips:\n",
        "    # if i > 0:\n",
        "    start = i*slice_duration\n",
        "    audio_clip = clip_audio(audio_data, sr, start, slice_duration, fx)\n",
        "    frames.append( audio_clip ) #fade_audio(audio_clip, fade_in, fade_out) )\n",
        "  return frames\n",
        "\n",
        "def apply_fx():\n",
        "  return\n",
        "\n",
        "# Clip audio signal\n",
        "# Returns clipped audio siangl\n",
        "def clip_audio(audio_data, sr=44100, start=0, duration=10, fx=[], oneshots=False):\n",
        "  xstart = librosa.time_to_samples(start, sr=sr)\n",
        "  xduration = librosa.time_to_samples(start+duration, sr=sr)\n",
        "  if audio_data.ndim > 1:\n",
        "    audio_data = audio_data[:, xstart:xduration]\n",
        "  else:\n",
        "    audio_data = audio_data[xstart:xduration]\n",
        "  return audio_data\n",
        "\n",
        "# Apply fade in and/or fade out to audio signal\n",
        "# Returns faded audio signal\n",
        "def fade_audio(audio_data, fade_in=0, fade_out=0, sr=44100):\n",
        "  a_duration = librosa.get_duration(audio_data, sr=sr)\n",
        "  if fade_in > 0:\n",
        "    fade_in_to = librosa.time_to_samples(fade_in, sr=sr)\n",
        "    in_y = audio_data[:, 0:fade_in_to]\n",
        "    fade_ins = []\n",
        "    for channel in in_y:\n",
        "      fade = [ i/len(channel)*smp for i, smp in enumerate(channel) ]\n",
        "      fade_ins.append(fade)\n",
        "    fade_ins = np.array(fade_ins)\n",
        "    tail_start = fade_in_to+1  \n",
        "    tail = audio_data[:, tail_start:]\n",
        "    audio_data = np.concatenate([fade_ins, tail], axis=1)\n",
        "  if fade_out > 0:\n",
        "    fade_out_start = librosa.time_to_samples(a_duration-fade_out, sr=sr)\n",
        "    out_y = audio_data[:, fade_out_start:]\n",
        "    fade_outs = []\n",
        "    for channel in out_y:\n",
        "      fade = [ smp-(i/len(channel)*smp) for i, smp in enumerate(channel) ]\n",
        "      fade_outs.append(fade)\n",
        "    fade_outs = np.array(fade_outs)\n",
        "    head_start = fade_out_start-1\n",
        "    head = audio_data[:, :head_start]\n",
        "    audio_data = np.concatenate([head, fade_outs], axis=1)\n",
        "  return audio_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def replicate(arr, times):\n",
        "  return [val for val in arr for _ in range(times)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "output.clear()\n",
        "# !nvidia-smi\n",
        "op(c.ok, 'Setup finished.', time=True)"
      ],
      "metadata": {
        "id": "Zl44n6FXsbnY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Autotune audio to scale or nearest note { vertical-output: true, form-width: \"30%\" }\n",
        "\n",
        "audio_to_autotune = \"\"  #@param {type: \"string\"}\n",
        "correction_method = \"scale\" #@param [\"scale\", \"nearest_note\"]\n",
        "\n",
        "#@markdown <small>Note that `scale` will be ignored if you have chosen _nearest_note_ as `correction_method` in the menu above.</small>\n",
        "scale = \"C:maj\" #@param ['C:min', 'C#:min', 'C:maj', 'C#:maj', 'D:min', 'D#:min', 'Db:min', 'D:maj', 'D#:maj', 'Db:maj', 'E:min', 'Eb:min', 'E:maj', 'Eb:maj', 'F:min', 'F#:min', 'F:maj', 'F#:maj', 'G:min', 'G#:min', 'Gb:min', 'G:maj', 'G#:maj', 'Gb:maj', 'A:min', 'A#:min', 'Ab:min', 'A:maj', 'A#:maj', 'Ab:maj', 'B:min', 'Bb:min', 'B:maj', 'Bb:maj']\n",
        "\n",
        "\n",
        "\n",
        "output_dir = \"\"  #@param {type: \"string\"}\n",
        "stereo_width = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "\n",
        "stereo = True\n",
        "if stereo_width == 0:\n",
        "  stereo = False\n",
        "\n",
        "\n",
        "#--\n",
        "\n",
        "uniq_id = gen_id()\n",
        "input = audio_to_autotune\n",
        "\n",
        "if os.path.isfile(drive_root+input):\n",
        "  inputs = [drive_root+input]\n",
        "  dir_in = path_dir(drive_root+input)\n",
        "elif input != '' and os.path.isdir(drive_root+input):\n",
        "  dir_in = drive_root+fix_path(input)\n",
        "  # What to do if input is directory path\n",
        "  inputs = list_audio(dir_in) #glob(dir_in+'/*')\n",
        "elif os.path.isdir(drive_root+input) and '*' in input:\n",
        "  dir_in = path_dir(drive_root+input)\n",
        "  inputs = glob(drive_root+input)\n",
        "else:\n",
        "  op(c.fail, 'FAIL!', 'Input should be a path to a file or a directory.')\n",
        "  sys.exit('Input not understood.')\n",
        "\n",
        "# Output\n",
        "if output_dir == '':\n",
        "  dir_out = dir_in\n",
        "else:\n",
        "  if not os.path.isdir(drive_root+output_dir):\n",
        "    os.mkdir(drive_root+output_dir)\n",
        "  dir_out = drive_root+fix_path(output_dir)\n",
        "  \n",
        "timer_start = time.time()\n",
        "total = len(inputs)\n",
        "\n",
        "correction_function = closest_pitch if correction_method == 'nearest_note' else partial(aclosest_pitch_from_scale, scale=scale)\n",
        "\n",
        "# -- DO THINGS --\n",
        "# print( dir_in )\n",
        "# print( dir_out )\n",
        "\n",
        "op(c.title, 'Run ID:', uniq_id)\n",
        "print()\n",
        "\n",
        "for i, input in enumerate(inputs, 1):\n",
        "  ndx_info = str(i)+'/'+str(total)+' '\n",
        "  op(c.title, ndx_info+'Processing', input.replace(drive_root, ''), time=True)\n",
        "  print()\n",
        "\n",
        "  file_wav_in = input\n",
        "  file_wav_out = dir_out+gen_id()+'_'+str(i).zfill(3)+'.wav'\n",
        "\n",
        "  op(c.title, 'Source audio')\n",
        "  audio_player(file_wav_in)\n",
        "\n",
        "  y, sr = librosa.load(file_wav_in, sr=None, mono=False if stereo == True else True)\n",
        "\n",
        "  if stereo == False:\n",
        "    if y.ndim > 1:\n",
        "      y = y[0: :]\n",
        "    pitch_corrected_y = autotune(y, sr, correction_function)\n",
        "    sf.write(file_wav_out, pitch_corrected_y, sr)\n",
        "    audio_player(file_wav_out)\n",
        "\n",
        "  else:\n",
        "    channel_files = []\n",
        "    for i, channel in enumerate(y):\n",
        "      channel_name = 'left' if i == 0 else 'right'\n",
        "      tmp_wav = dir_tmp+uniq_id+'_'+channel_name+'.wav'\n",
        "      pitch_corrected_y = autotune(channel, sr, correction_function)\n",
        "      sf.write(tmp_wav, pitch_corrected_y, sr)\n",
        "\n",
        "      # op(c.title, 'Result', time=True)\n",
        "      # audio_player(file_wav_out)\n",
        "\n",
        "    left, _ = librosa.load(dir_tmp+uniq_id+'_left.wav', sr=None, mono=True)\n",
        "    right, _ = librosa.load(dir_tmp+uniq_id+'_right.wav', sr=None, mono=True)\n",
        "    final_audio = narrow_stereo(left, right, 0.75)\n",
        "\n",
        "    print()\n",
        "    op(c.title, 'Result audio')\n",
        "    sf.write(file_wav_out, final_audio.T, sr)\n",
        "    \n",
        "    if os.path.isfile(file_wav_out):\n",
        "      audio_player(file_wav_out)\n",
        "      print()\n",
        "      op(c.ok, 'Autotuned WAV saved as', file_wav_out.replace(drive_root, ''), time=True)\n",
        "    else:\n",
        "      op(c.fail, 'ERROR saving', file_wav_out.replace(drive_root, ''), time=True)\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -- END THINGS --\n",
        "\n",
        "timer_end = time.time()\n",
        "\n",
        "print()\n",
        "op(c.okb, 'Elapsed', timedelta(seconds=timer_end-timer_start), time=True)\n",
        "op(c.ok, 'FIN.')\n",
        "\n"
      ],
      "metadata": {
        "id": "Znu4P-Gtsdrr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Autotune audio to another audio { vertical-output: true, form-width: \"30%\" }\n",
        "\n",
        "audio_to_autotune = \"\"  #@param {type: \"string\"}\n",
        "pitch_source_audio = \"\"  #@param {type: \"string\"}\n",
        "\n",
        "result_length = \"audio_to_autotune\" #@param [\"audio_to_autotune\", \"pitch_source_audio\"]\n",
        "\n",
        "output_dir = \"\"  #@param {type: \"string\"}\n",
        "stereo_width = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "\n",
        "stereo = True\n",
        "if stereo_width == 0:\n",
        "  stereo = False\n",
        "\n",
        "\n",
        "#--\n",
        "\n",
        "uniq_id = gen_id()\n",
        "input = audio_to_autotune\n",
        "\n",
        "if os.path.isfile(drive_root+input):\n",
        "  inputs = [drive_root+input]\n",
        "  dir_in = path_dir(drive_root+input)\n",
        "elif input != '' and os.path.isdir(drive_root+input):\n",
        "  dir_in = drive_root+fix_path(input)\n",
        "  # What to do if input is directory path\n",
        "  inputs = list_audio(dir_in) #glob(dir_in+'/*')\n",
        "elif os.path.isdir(drive_root+input) and '*' in input:\n",
        "  dir_in = path_dir(drive_root+input)\n",
        "  inputs = glob(drive_root+input)\n",
        "else:\n",
        "  op(c.fail, 'FAIL!', 'Input should be a path to a file or a directory.')\n",
        "  sys.exit('Input not understood.')\n",
        "\n",
        "pitch_source_audio = drive_root+pitch_source_audio\n",
        "if not os.path.isfile(pitch_source_audio):\n",
        "  sys.exit('pitch_source_audio should point to an audio file located in your Google Drive, e.g. audio/vocals/test.wav')\n",
        "\n",
        "# Output\n",
        "if output_dir == '':\n",
        "  dir_out = dir_in\n",
        "else:\n",
        "  if not os.path.isdir(drive_root+output_dir):\n",
        "    os.mkdir(drive_root+output_dir)\n",
        "  dir_out = drive_root+fix_path(output_dir)\n",
        "  \n",
        "timer_start = time.time()\n",
        "total = len(inputs)\n",
        "\n",
        "\n",
        "\n",
        "# melody = get_melody(pitch_y, pitch_sr)\n",
        "# total_notes = len(melody)\n",
        "\n",
        "# print('melody', melody)\n",
        "\n",
        "# correction_function = partial(aclosest_pitch_from_melody, sr)\n",
        "\n",
        "# -- DO THINGS --\n",
        "# print( dir_in )\n",
        "# print( dir_out )\n",
        "\n",
        "op(c.title, 'Run ID:', uniq_id)\n",
        "print()\n",
        "\n",
        "for i, input in enumerate(inputs, 1):\n",
        "  ndx_info = str(i)+'/'+str(total)+' '\n",
        "  op(c.title, ndx_info+'Processing', input.replace(drive_root, ''), time=True)\n",
        "  print()\n",
        "\n",
        "  file_wav_in = input\n",
        "\n",
        "  op(c.title, 'Source audio')\n",
        "  audio_player(file_wav_in)\n",
        "\n",
        "  op(c.title, 'Pitch audio')\n",
        "  audio_player(pitch_source_audio)\n",
        "\n",
        "  file_wav_out = dir_out+gen_id()+'_'+str(i).zfill(3)+'.wav'\n",
        "\n",
        "  y, sr = librosa.load(file_wav_in, sr=None, mono=False if stereo == True else True)\n",
        "  audio_duration = librosa.get_duration(y, sr)\n",
        "\n",
        "  # op(c.okb, 'Estimated duration of notation:', notation_duration )\n",
        "  # op(c.okb, 'Audio duration:', audio_duration )\n",
        "\n",
        "  # if audio_duration < pitch_source_duration or timestretch_audio == 'always':\n",
        "\n",
        "  pitch_y, pitch_sr = librosa.load(pitch_source_audio, sr=None, mono=True)\n",
        "  pitch_source_duration = librosa.get_duration(pitch_y, pitch_sr)\n",
        "\n",
        "  print()\n",
        "  if result_length == \"audio_to_autotune\":\n",
        "    pitch_y = time_stretch_audio(pitch_y, sr, audio_duration)\n",
        "  else:\n",
        "    op(c.okb, 'Time stretching audio to '+str(round(100*(audio_duration/pitch_source_duration), 2))+' % speed, from '+str(round(audio_duration, 4))+' to '+str(pitch_source_duration)+' seconds...', time=True)\n",
        "    stretched_audio = time_stretch_audio(y, sr, pitch_source_duration)\n",
        "  \n",
        "  if stereo == False:\n",
        "    if stretched_audio.ndim > 1:\n",
        "      stretched_audio = stretched_audio[0: :]\n",
        "    pitch_corrected_y = wav2wav_autotune(stretched_audio, pitch_y, sr)\n",
        "    sf.write(file_wav_out, pitch_corrected_y, sr)\n",
        "    audio_player(file_wav_out)\n",
        "\n",
        "  else:\n",
        "    channel_files = []\n",
        "    for i, channel in enumerate(stretched_audio):\n",
        "      channel_name = 'left' if i == 0 else 'right'\n",
        "      tmp_wav = dir_tmp+uniq_id+'_'+channel_name+'.wav'\n",
        "      pitch_corrected_y = wav2wav_autotune(channel, pitch_y, sr)\n",
        "      sf.write(tmp_wav, pitch_corrected_y, sr)\n",
        "\n",
        "      # op(c.title, 'Result', time=True)\n",
        "      # audio_player(file_wav_out)\n",
        "\n",
        "    left, _ = librosa.load(dir_tmp+uniq_id+'_left.wav', sr=None, mono=True)\n",
        "    right, _ = librosa.load(dir_tmp+uniq_id+'_right.wav', sr=None, mono=True)\n",
        "    final_audio = narrow_stereo(left, right, 0.75)\n",
        "\n",
        "    print()\n",
        "    op(c.title, 'Result audio')\n",
        "    sf.write(file_wav_out, final_audio.T, sr)\n",
        "    \n",
        "    if os.path.isfile(file_wav_out):\n",
        "      audio_player(file_wav_out)\n",
        "      print()\n",
        "      op(c.ok, 'Autotuned WAV saved as', file_wav_out.replace(drive_root, ''), time=True)\n",
        "    else:\n",
        "      op(c.fail, 'ERROR saving', file_wav_out.replace(drive_root, ''), time=True)\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -- END THINGS --\n",
        "\n",
        "timer_end = time.time()\n",
        "\n",
        "print()\n",
        "op(c.okb, 'Elapsed', timedelta(seconds=timer_end-timer_start), time=True)\n",
        "op(c.ok, 'FIN.')\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cBRBwcRrlt9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Autotune audio to [Chords Guru Turbo 100a Deluxe](https://ki.gy/cv) chord progression { vertical-output: true, form-width: \"30%\" }\n",
        "\n",
        "audio_to_autotune = \"\"  #@param {type: \"string\"}\n",
        "## midi_input = \"temp/midilab/legnaf_2_right_131bpm_128notes_16.0s.mid\"  #@param {type: \"string\"}\n",
        "\n",
        "magic_string = \"\" #@param {type: \"string\"}\n",
        "\n",
        "# chords_per_bar = 1 #@param {type:\"slider\", min:1, max:4, step:1}\n",
        "# bpm = 120 #@param {type: \"integer\"}\n",
        "\n",
        "output_dir = \"\"  #@param {type: \"string\"}\n",
        "stereo_width = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "timestretch_audio = \"auto\" #@param [\"auto\", \"always\"]\n",
        "\n",
        "bpm, chords_per_bar, chords_string = magic_string.split(';')\n",
        "\n",
        "stereo = True\n",
        "if stereo_width == 0:\n",
        "  stereo = False\n",
        "\n",
        "\n",
        "\n",
        "#--\n",
        "\n",
        "uniq_id = gen_id()\n",
        "input = audio_to_autotune\n",
        "\n",
        "if os.path.isfile(drive_root+input):\n",
        "  inputs = [drive_root+input]\n",
        "  dir_in = path_dir(drive_root+input)\n",
        "elif input != '' and os.path.isdir(drive_root+input):\n",
        "  dir_in = drive_root+fix_path(input)\n",
        "  # What to do if input is directory path\n",
        "  inputs = list_audio(dir_in) #glob(dir_in+'/*')\n",
        "elif os.path.isdir(drive_root+input) and '*' in input:\n",
        "  dir_in = path_dir(drive_root+input)\n",
        "  inputs = glob(drive_root+input)\n",
        "else:\n",
        "  op(c.fail, 'FAIL!', 'Input should be a path to a file or a directory.')\n",
        "  sys.exit('Input not understood.')\n",
        "\n",
        "# Output\n",
        "if output_dir == '':\n",
        "  dir_out = dir_in\n",
        "else:\n",
        "  if not os.path.isdir(drive_root+output_dir):\n",
        "    os.mkdir(drive_root+output_dir)\n",
        "  dir_out = drive_root+fix_path(output_dir)\n",
        "  \n",
        "timer_start = time.time()\n",
        "total = len(inputs)\n",
        "\n",
        "chords = chords_string.split('|')\n",
        "total_chords = len(chords)\n",
        "notation_duration = 60/bpm * (4*total_chords)\n",
        "\n",
        "if chords_per_bar > 0:\n",
        "  chords = replicate(chords, chords_per_bar)\n",
        "\n",
        "# -- \n",
        "\n",
        "op(c.title, 'Run ID:', uniq_id)\n",
        "print()\n",
        "\n",
        "for i, input in enumerate(inputs, 1):\n",
        "  ndx_info = str(i)+'/'+str(total)+' '\n",
        "  op(c.title, ndx_info+'Processing', input.replace(drive_root, ''), time=True)\n",
        "  print()\n",
        "  \n",
        "  file_wav_in = input\n",
        "\n",
        "  op(c.title, 'Source audio')\n",
        "  audio_player(file_wav_in)\n",
        "\n",
        "  file_wav_out = dir_out+gen_id()+'_'+str(i).zfill(3)+'.wav'\n",
        "\n",
        "  y, sr = librosa.load(file_wav_in, sr=None, mono=False if stereo == True else True)\n",
        "\n",
        "  audio_duration = librosa.get_duration(y, sr)\n",
        "\n",
        "  # op(c.okb, 'Estimated duration of notation:', notation_duration )\n",
        "  # op(c.okb, 'Audio duration:', audio_duration )\n",
        "\n",
        "  if audio_duration < notation_duration or timestretch_audio == 'always':\n",
        "    print()\n",
        "    op(c.okb, 'Time stretching audio to '+str(round(100*(audio_duration/notation_duration), 2))+' % speed, from '+str(round(audio_duration, 4))+' to '+str(notation_duration)+' seconds...', time=True)\n",
        "    stretched_audio = time_stretch_audio(y, sr, notation_duration)\n",
        "    stretched_audio_slices = slice_to_frames(y, sr, notation_duration/total_chords)\n",
        "  else:\n",
        "    stretched_audio_slices = [y]\n",
        "\n",
        "  total_audio_clips = len(stretched_audio_slices)\n",
        "  # op(c.okb, 'Processing '+str(total_audio_clips)+' audio frames...', time=True)\n",
        "\n",
        "  all_audio_slices = []\n",
        "\n",
        "  for ii, audio_slice in enumerate(stretched_audio_slices):\n",
        "    ndx_info_ii = str(ii+1)+'/'+str(total_audio_clips)+' '\n",
        "    # op(c.okb, ndx_info_ii+'Processing slice...', time=True)\n",
        "    slice_y = audio_slice\n",
        "\n",
        "    slice_wav_out = dir_tmp+uniq_id+'_slice_'+str(i).zfill(3)+'_'+str(ii).zfill(3)+'.wav'\n",
        "    correction_function = partial(aclosest_pitch_from_notes, notes_string=chords[ii])\n",
        "\n",
        "    if stereo == False:\n",
        "      if slice_y.ndim > 1:\n",
        "        slice_y = slice_y[0: :]\n",
        "      pitch_corrected_y = autotune(slice_y, sr, correction_function)\n",
        "      sf.write(slice_wav_out, pitch_corrected_y, sr)\n",
        "      # audio_player(slice_wav_out)\n",
        "\n",
        "    else:\n",
        "      channel_files = []\n",
        "      for iii, channel in enumerate(slice_y):\n",
        "        channel_name = 'left' if iii == 0 else 'right'\n",
        "        slice_wav_out = dir_tmp+uniq_id+'_slice_'+str(i).zfill(3)+'_'+str(ii).zfill(3)+'_'+channel_name+'.wav'\n",
        "        pitch_corrected_y = autotune(channel, sr, correction_function)\n",
        "        sf.write(slice_wav_out, pitch_corrected_y, sr)\n",
        "\n",
        "        # op(c.title, 'Result', time=True)\n",
        "        # audio_player(file_wav_out)\n",
        "\n",
        "      left, _ = librosa.load(dir_tmp+uniq_id+'_slice_'+str(i).zfill(3)+'_'+str(ii).zfill(3)+'_left.wav', sr=None, mono=True)\n",
        "      right, _ = librosa.load(dir_tmp+uniq_id+'_slice_'+str(i).zfill(3)+'_'+str(ii).zfill(3)+'_right.wav', sr=None, mono=True)\n",
        "      final_slice = narrow_stereo(left, right, stereo_width)\n",
        "      sf.write(slice_wav_out, final_slice.T, sr)\n",
        "      if os.path.isfile(slice_wav_out):\n",
        "        # audio_player(slice_wav_out)\n",
        "        all_audio_slices.append(final_slice)\n",
        "      else:\n",
        "        op(c.fail, 'Error saving', slice_wav_out.replace(drive_root, ''), time=True)\n",
        "\n",
        "  audio_concat = np.concatenate(all_audio_slices, axis=1)\n",
        "\n",
        "  print()\n",
        "  op(c.title, 'Result audio')\n",
        "  sf.write(file_wav_out, audio_concat.T, sr)\n",
        "  \n",
        "  if os.path.isfile(file_wav_out):\n",
        "    audio_player(file_wav_out)\n",
        "    print()\n",
        "    op(c.ok, 'Autotuned WAV saved as', file_wav_out.replace(drive_root, ''), time=True)\n",
        "  else:\n",
        "    op(c.fail, 'ERROR saving', file_wav_out.replace(drive_root, ''), time=True)\n",
        "  print()\n",
        "\n",
        "  # print('test 1')\n",
        "  # sf.write('test1.wav', audio_concat.T, sr)\n",
        "  # audio_player('test1.wav')\n",
        "\n",
        "  # sf.write(file_wav_out, concat_y.T, sr)\n",
        "  # audio_player(file_wav_out)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -- END THINGS --\n",
        "\n",
        "timer_end = time.time()\n",
        "\n",
        "print()\n",
        "op(c.okb, 'Elapsed', timedelta(seconds=timer_end-timer_start), time=True)\n",
        "op(c.ok, 'FIN.')\n",
        "\n"
      ],
      "metadata": {
        "id": "MkbUaYPZeWuS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}