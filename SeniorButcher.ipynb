{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeniorButcher.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zWtfhMuVhDlBvy8nKtLHf9kh7NSFfMLh",
      "authorship_tag": "ABX9TyMW7dLzlXaL3ICRe50cYEfc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olaviinha/SloppyButchery/blob/main/SeniorButcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJQKfEOJmd7l"
      },
      "source": [
        "#<font face=\"Trebuchet MS\" size=\"6\">Senior Butcher <font color=\"#999\" size=\"3\">v 0.0.4<font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font size=\"4\">Sloppy Butchery @</font> <a href=\"https://github.com/olaviinha/SloppyButchery\" target=\"_blank\"><font color=\"#999\" size=\"4\">Github</font></a><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font size=\"3\" color=\"#999\"><a href=\"https://inha.se\" target=\"_blank\"><font color=\"#999\">O. Inha</font></a></font></font>\n",
        "\n",
        "Senior Butcher High Precision Beat Slicer improves the precision of beat tracking with audio analysis libraries and tools such as Librosa, Essentia, or Aubio. This notebook uses [Essentia](https://github.com/MTG/essentia) for initial beat tracking. Essentia and [Librosa](https://github.com/librosa/librosa) are both used for further audio analysis. See [details in Github](https://github.com/olaviinha/SeniorButcherBeatSlicer).\n",
        "\n",
        "### Howto\n",
        "1. Input a path to an audiofile located in your Google Drive.\n",
        "2. Hit <i>Runtime > Run all</i>.\n",
        "\n",
        "<hr size=\"1\" color=\"#666\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liT0KnmLehzd",
        "cellView": "form"
      },
      "source": [
        "#@title #Setup\n",
        "#@markdown This cell needs to be run only once. It will mount your Google Drive and setup prerequisites.\n",
        "\n",
        "import os\n",
        "from google.colab import output\n",
        "force_setup = False\n",
        "\n",
        "pip_packages = 'spleeter essentia ffmpeg-python'\n",
        "\n",
        "# inhagcutils\n",
        "if not os.path.isfile('/content/inhagcutils.ipynb') and force_setup == False:\n",
        "  %cd /content/\n",
        "  !pip -q install import-ipynb {pip_packages}\n",
        "  !curl -s -O https://raw.githubusercontent.com/olaviinha/inhagcutils/master/inhagcutils.ipynb\n",
        "import import_ipynb\n",
        "from inhagcutils import *\n",
        "\n",
        "# Mount Drive\n",
        "if not os.path.isdir('/content/drive') and force_setup == False:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "# Drive symlink\n",
        "if not os.path.isdir('/content/mydrive') and force_setup == False:\n",
        "  os.symlink('/content/drive/My Drive', '/content/mydrive')\n",
        "  drive_root_set = True\n",
        "drive_root = '/content/mydrive/'\n",
        "\n",
        "dir_tmp = '/content/tmp/'\n",
        "create_dirs([dir_tmp])\n",
        "last_data_file = ''\n",
        "\n",
        "output.clear()\n",
        "op(c.ok, 'Setup finished.')\n",
        "\n",
        "##------------------------------------------------------------\n",
        "##\n",
        "## Imports & Defs\n",
        "##\n",
        "##------------------------------------------------------------\n",
        "\n",
        "import soundfile\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "nper = np.seterr(divide = 'ignore') \n",
        "\n",
        "output.clear()\n",
        "op(c.ok, 'Setup finished.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NkUr-Sqkw9-",
        "cellView": "form"
      },
      "source": [
        "#@title #Slice\n",
        "input_audio = \"\" #@param {type:\"string\"}\n",
        "#@markdown <font size=\"3\" color=\"#888\">Slices will be saved in the same directory, under a new subdirectory named after the input file<br><font size=\"4\">`<path to input audio file>/<input_audio filename>/0001.wav`</font> etc.</font>\n",
        "\n",
        "input_audio = drive_root+input_audio\n",
        "output_dir = fix_path(path_dir(input_audio)+slug(basename(input_audio)))\n",
        "dir_tmp = '/content/tmp/'\n",
        "dir_converted = dir_tmp+'converted/'\n",
        "dir_spleet = dir_tmp+'spleet/'\n",
        "sr = 44100\n",
        "create_dirs([dir_tmp, dir_converted, dir_spleet, output_dir])\n",
        "\n",
        "import sys, time, soundfile, librosa, warnings\n",
        "import numpy as np\n",
        "import essentia\n",
        "import essentia.standard\n",
        "import essentia.streaming\n",
        "from essentia import Pool, array\n",
        "from essentia.standard import *\n",
        "from spleeter.separator import Separator\n",
        "from spleeter.audio.adapter import AudioAdapter\n",
        "\n",
        "def get_beats(audio, sr):\n",
        "  # You may use any library or tool for initial beat tracking here\n",
        "  # for as long as it returns beat starting positions in seconds.\n",
        "  bt = BeatTrackerMultiFeature()\n",
        "  beats, _ = bt(audio)\n",
        "  return beats\n",
        "\n",
        "def get_differences(blist, round=0):\n",
        "  x = list(np.array(blist.tolist()).flatten())\n",
        "  xdiff = [x[n]-x[n-1] for n in range(1,len(x))]\n",
        "  if round > 0:\n",
        "    rounded = [ '%.2f' % el for el in xdiff ]\n",
        "    return rounded\n",
        "  else:\n",
        "    return xdiff\n",
        "\n",
        "def most_frequent(list):\n",
        "  freq = max(set(list), key = list.count)\n",
        "  return freq\n",
        "\n",
        "def filter_durations(durations, range, decs):\n",
        "  filtered_durations = []\n",
        "  for duration in durations:\n",
        "    duration = float(duration)\n",
        "    range = float(range)\n",
        "    if round(duration, decs) == range:\n",
        "      filtered_durations.append(duration)\n",
        "  return filtered_durations\n",
        "\n",
        "def get_tail_peaks(audio, nudgeTime=False, wat=''):\n",
        "  dur = librosa.get_duration(audio, sr=sr)\n",
        "  nudged = False\n",
        "  minPos = 0.96\n",
        "  minPeakDis = 0.001\n",
        "  th = 0.4\n",
        "  pos, amp = PeakDetection(threshold=th, minPeakDistance=minPeakDis, minPosition=minPos)(audio.astype(np.float32))\n",
        "  if len(pos) > 0:\n",
        "    # This slice needs handling\n",
        "    for i, peak in enumerate(pos):\n",
        "      if amp[i] > th and nudged == False:\n",
        "        nudgePeak = peak\n",
        "        nudged = True\n",
        "  if nudgeTime == True and nudged == True:\n",
        "    return nudgePeak\n",
        "  elif nudgeTime == True and nudged == False:\n",
        "    return 0\n",
        "  else:\n",
        "    if wat == 'amp':\n",
        "      return amp\n",
        "    else:\n",
        "      return dur-(pos*dur)\n",
        "\n",
        "def nudge(beats, timing_track, anal_duration, real_duration, timetravel=0, return_type='time', starting_beat=0, sr=44100):\n",
        "  beat_positions = []\n",
        "  a = 0\n",
        "  for i, beat in enumerate(beats):\n",
        "    if i > starting_beat:\n",
        "      # Get slice\n",
        "      s_time = beat+timetravel\n",
        "      e_time = anal_duration-a\n",
        "      s_sample = librosa.time_to_samples(s_time, sr=sr)\n",
        "      e_sample = librosa.time_to_samples(s_time+e_time, sr=sr)\n",
        "      beat_timing = timing_track[s_sample:e_sample]\n",
        "\n",
        "      # Nudge\n",
        "      nudge_peak = get_tail_peaks(beat_timing, True)\n",
        "      if nudge_peak > 0:\n",
        "        ns_time = s_time-(anal_duration-anal_duration*nudge_peak)-a\n",
        "        ns_sample = librosa.time_to_samples(ns_time, sr=sr)\n",
        "      else:\n",
        "        ns_time = s_time\n",
        "        ns_sample = s_sample\n",
        "      ns_sample = librosa.time_to_samples(ns_time-timetravel, sr=sr)\n",
        "      ne_sample = librosa.time_to_samples(ns_time+(real_duration-a), sr=sr)\n",
        "\n",
        "      # Return start:end of each beat in either 'samples' or in 'seconds'\n",
        "      if return_type == 'samples':\n",
        "        beat_positions.append([ns_sample, ne_sample])\n",
        "      else:\n",
        "        beat_positions.append([ns_time, ns_time+(real_duration-a)])\n",
        "  return beat_positions\n",
        "\n",
        "def write_slices(beat_sample_ranges, audio_track, output_dir):\n",
        "  pad = 5\n",
        "  for i, beat in enumerate(beat_sample_ranges):\n",
        "    beat_audio = audio_track[:, beat[0]:beat[1]]\n",
        "    wav_out_file = output_dir+str(i).zfill(pad)+'.wav'\n",
        "    soundfile.write(wav_out_file, beat_audio.T, sr)\n",
        "\n",
        "def waveform(input, dur=None, peaks=[], sr=44100):\n",
        "\n",
        "  if type(input) is np.ndarray:\n",
        "    data = input\n",
        "  else:\n",
        "    data, sr = librosa.load(input, sr=sr, duration=dur, offset=0.0)\n",
        "  plt.rcParams['axes.facecolor'] = plot_bg\n",
        "  fig = plt.figure(figsize=(16, 5), frameon=False)\n",
        "  #ax = fig.add_axes([0, 0, 1, 1])\n",
        "  #ax.axis('off')\n",
        "  if len(peaks) > 0:\n",
        "    for peak in peaks:\n",
        "      plt.axvline(x=peak, color='r')\n",
        "  #plt.plot(data, color=plot_wav)\n",
        "  librosa.display.waveplot(data, sr=sr, color=plot_wav)\n",
        "  plt.show()\n",
        "\n",
        "def display_beats(beat_sample_ranges, audio_track):\n",
        "  for i, beat in enumerate(beat_sample_ranges):\n",
        "    waveform(audio_track[:, beat[0]:beat[1]])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "start_point = time.time()\n",
        "conv_point = time.time()\n",
        "op(c.title, 'Processing', path_leaf(input_audio))\n",
        "\n",
        "print('\\nConvert input file...')\n",
        "output = dir_converted+slug(basename(input_audio))+'.wav'\n",
        "!ffmpeg {ffmpeg_q} -y -i \"{input_audio}\" {wav_44} \"{output}\"\n",
        "\n",
        "print('Done in', round(time.time()-conv_point, 3), 'seconds.')\n",
        "\n",
        "spleet_point = time.time()\n",
        "print('\\nDrum track extraction for timing...')\n",
        "warnings.filterwarnings('ignore')\n",
        "# separator = Separator('spleeter:4stems')\n",
        "# audio_loader = AudioAdapter.default()\n",
        "audio_track, sr = librosa.load(output, sr=sr, mono=False)\n",
        "# audio_track, _ = audio_loader.load(output, sample_rate=sr)\n",
        "# drum_track = separator.separate(audio_track.T)['drums']\n",
        "# drum_track = separator.separate(audio_track)['drums']\n",
        "# print( drum_track )\n",
        "# separator.separate_to_file(input_audio, '/content/tmp/timing.wav')\n",
        "# timing_track = librosa.to_mono(drum_track.T)\n",
        "# timing_track, _ = librosa.load('/content/tmp/timing.wav', sr=sr, mono=True)\n",
        "!spleeter separate -o \"{dir_spleet}\" -p spleeter:4stems \"{input_audio}\"\n",
        "timing_track, _ = librosa.load(dir_spleet+basename(input_audio)+'/drums.wav', sr=sr, mono=True)\n",
        "print('Done in', round(time.time()-spleet_point, 3), 'seconds.')\n",
        "\n",
        "# Get beats\n",
        "track_point = time.time()\n",
        "print('\\nInitial beat tracking...')\n",
        "beats = get_beats(timing_track, sr)\n",
        "print('Done in', round(time.time()-spleet_point, 3), 'seconds.')\n",
        "\n",
        "# Analyze durations\n",
        "duration_point = time.time()\n",
        "print('\\nDecomposing lossy compression of beat interval distribution...')\n",
        "decs = 2\n",
        "precise_durations = get_differences(beats, 0)\n",
        "compressed_durations = get_differences(beats, decs)\n",
        "duration_range = most_frequent(compressed_durations)\n",
        "filtered_durations = filter_durations(precise_durations, duration_range, decs)\n",
        "xs_beat = min(filtered_durations)\n",
        "xl_beat = max(filtered_durations)+0.02\n",
        "print('Done in', round(time.time()-duration_point, 3), 'seconds.')\n",
        "\n",
        "anal_point = time.time()\n",
        "print('\\nShave tail peak clusters...')\n",
        "nudged_beats = nudge(beats, timing_track, xl_beat, xs_beat, 0, 'samples')\n",
        "print('Done in', round(time.time()-anal_point, 3), 'seconds.')\n",
        "\n",
        "\n",
        "\n",
        "write_point = time.time()\n",
        "print('\\nWrite slices to WAV files...')\n",
        "write_slices(nudged_beats, audio_track, output_dir)\n",
        "print('Done in', round(time.time()-write_point, 3), 'seconds.')\n",
        "\n",
        "print('\\nSlices can be found from', output_dir.replace(drive_root, ''))\n",
        "print('Entire process took', round(time.time()-start_point, 3), 'seconds.')\n",
        "\n",
        "op(c.title, 'FIN')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}