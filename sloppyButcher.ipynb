{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sloppyButcher.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1xIPcZOmDgL-jFhxNs5saGFuU_hl16xIV",
      "authorship_tag": "ABX9TyMCBuJDjCGGyFiLucvXoSq6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olaviinha/SloppyButchery/blob/main/sloppyButcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLn5trdcQbL6"
      },
      "source": [
        "#<font face=\"Trebuchet MS\" size=\"6\">Sloppy Butcher <font color=\"#999\" size=\"3\">v 0.2.0<font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font size=\"4\">Sloppy Butchery @</font> <a href=\"https://github.com/olaviinha/SloppyButchery\" target=\"_blank\"><font color=\"#999\" size=\"4\">Github</font></a><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font size=\"3\" color=\"#999\"><a href=\"https://inha.se\" target=\"_blank\"><font color=\"#999\">O. Inha</font></a></font></font>\n",
        "\n",
        "Sloppy Butcher is an audio power-chopper and randomizer. It takes a directory of audio files, chops it up, shuffles it, and frankensteins it into a single audio file.\n",
        "\n",
        "###Quick start\n",
        "1.   Create a directory in your Google Drive called `sloppybutcher`\n",
        "2.   Drop a few longish audio files in it (and wait until Drive sync complete).\n",
        "3.   Hit <i>Runtime > Run all</i> from the menu.\n",
        "\n",
        "Sloppy Butcher is powered by Librosa, SoX and FFmpeg.\n",
        "\n",
        "<hr size=\"1\" color=\"#666\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNn8OyeGOrlP",
        "cellView": "form"
      },
      "source": [
        "#@title #Setup\n",
        "#@markdown This cell needs to be run only once. It will mount your Google Drive and setup prerequisities.\n",
        "import os\n",
        "from google.colab import output\n",
        "force_setup = False\n",
        "force_format = False\n",
        "\n",
        "apt_packages = 'sox'\n",
        "pip_packages = 'pysoundfile'\n",
        "pip_packages_beatslice = 'spleeter essentia ffmpeg-python'\n",
        "pip_packages_wordslice = 'deepspeech-gpu'\n",
        "\n",
        "show_info = False\n",
        "extra_verbose_performance = False\n",
        "\n",
        "# Setup\n",
        "if not 'setup_done' in globals() or force_setup == True:\n",
        "  import sys\n",
        "  hosted_runtime = 'google.colab' in sys.modules\n",
        "\n",
        "  if hosted_runtime == True:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    drive_root = \"/content/drive/My Drive/\"\n",
        "    dir_tmp = \"/content/tmp/\"\n",
        "    !mkdir {dir_tmp}\n",
        "    !gsutil -q -m cp -R gs://olaviinha/slicer {dir_tmp}\n",
        "    cleanup = False\n",
        "  else:\n",
        "    project_home = !pwd\n",
        "    project_home = project_home[0]\n",
        "    print('Running locally at', project_home, 'â€“ skipping Drive mount.')\n",
        "    drive_root = project_home\n",
        "    dir_tmp = project_home+\"/tmp/\"\n",
        "    !mkdir {dir_tmp}\n",
        "    cleanup = True\n",
        "\n",
        "  !apt-get install sox\n",
        "  !pip -q install import-ipynb {pip_packages}\n",
        "  !curl -s -O https://raw.githubusercontent.com/olaviinha/inhagcutils/master/inhagcutils.ipynb\n",
        "  import import_ipynb, soundfile\n",
        "  from inhagcutils import *\n",
        "  setup_done = True\n",
        "\n",
        "class c:\n",
        "  title = '\\033[96m'\n",
        "  ok = '\\033[92m'\n",
        "  okb = '\\033[94m'\n",
        "  warn = '\\033[93m'\n",
        "  fail = '\\033[91m'\n",
        "  endc = '\\033[0m'\n",
        "  bold = '\\033[1m'\n",
        "  u = '\\033[4m'\n",
        "\n",
        "def op(typex, msg):\n",
        "  print(typex+msg+c.endc)\n",
        "\n",
        "np.seterr(divide = 'ignore')\n",
        "\n",
        "# Format\n",
        "if not 'last_source_files' in globals() or force_format == True:\n",
        "  last_source_files = []\n",
        "if not 'last_conversion' in globals() or force_format == True:\n",
        "  last_conversion = []\n",
        "if not 'last_silence_amount' in globals() or force_format == True:\n",
        "  last_silence_amount = 0\n",
        "if not 'last_slices_per_beat' in globals() or force_format == True:\n",
        "  last_slices_per_beat = []\n",
        "if not 'last_bpm' in globals() or force_format == True:\n",
        "  last_bpm = 0\n",
        "if not 'last_reverse' in globals() or force_format == True:\n",
        "  last_reverse = False\n",
        "if not 'last_per_source_length' in globals() or force_format == True:\n",
        "  last_per_source_length = 0\n",
        "if not 'last_durations' in globals() or force_format == True:\n",
        "  last_durations = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------\n",
        "# --- Functions\n",
        "# ----------------------------------------------------------------------------------\n",
        "\n",
        "def separate_drums(audio_track):\n",
        "  warnings.filterwarnings('ignore')\n",
        "  separator = Separator('/content/cfg.json')\n",
        "  audio_loader = get_default_audio_adapter()\n",
        "  drum_track = separator.separate(audio_track.T)['drums']\n",
        "  return librosa.to_mono(drum_track.T)\n",
        "\n",
        "def separate_vocals(audio_track):\n",
        "  warnings.filterwarnings('ignore')\n",
        "  separator = Separator('/content/cfg.json')\n",
        "  audio_loader = get_default_audio_adapter()\n",
        "  vocal_track = separator.separate(audio_track.T)['vocals']\n",
        "  return librosa.to_mono(vocal_track.T)\n",
        "\n",
        "\n",
        "def get_beats(audio, sr=global_sr):\n",
        "  # You may use any library or tool for initial beat tracking here\n",
        "  # for as long as it returns beat starting positions in seconds.\n",
        "  bt = BeatTrackerMultiFeature()\n",
        "  beats, _ = bt(audio)\n",
        "  return beats\n",
        "\n",
        "def get_differences(blist, round=0):\n",
        "  x = list(np.array(blist.tolist()).flatten())\n",
        "  xdiff = [x[n]-x[n-1] for n in range(1,len(x))]\n",
        "  if round > 0:\n",
        "    rounded = [ '%.2f' % el for el in xdiff ]\n",
        "    return rounded\n",
        "  else:\n",
        "    return xdiff\n",
        "\n",
        "def most_frequent(list):\n",
        "  freq = max(set(list), key = list.count)\n",
        "  return freq\n",
        "\n",
        "def filter_durations(durations, range, decs):\n",
        "  filtered_durations = []\n",
        "  for duration in durations:\n",
        "    duration = float(duration)\n",
        "    range = float(range)\n",
        "    if round(duration, decs) == range:\n",
        "      filtered_durations.append(duration)\n",
        "  return filtered_durations\n",
        "\n",
        "def get_tail_peaks(audio, nudgeTime=False, wat=''):\n",
        "  dur = librosa.get_duration(audio, sr=sr)\n",
        "  nudged = False\n",
        "  minPos = 0.96\n",
        "  minPeakDis = 0.001\n",
        "  th = 0.4\n",
        "  pos, amp = PeakDetection(threshold=th, minPeakDistance=minPeakDis, minPosition=minPos)(audio.astype(np.float32))\n",
        "  if len(pos) > 0:\n",
        "    # This slice needs handling\n",
        "    for i, peak in enumerate(pos):\n",
        "      if amp[i] > th and nudged == False:\n",
        "        nudgePeak = peak\n",
        "        nudged = True\n",
        "  if nudgeTime == True and nudged == True:\n",
        "    return nudgePeak\n",
        "  elif nudgeTime == True and nudged == False:\n",
        "    return 0\n",
        "  else:\n",
        "    if wat == 'amp':\n",
        "      return amp\n",
        "    else:\n",
        "      return dur-(pos*dur)\n",
        "\n",
        "def nudge(beats, timing_track, anal_duration, real_duration, timetravel, return_type='time', starting_beat=0, sr=global_sr):\n",
        "  beat_positions = []\n",
        "  a = 0\n",
        "  for i, beat in enumerate(beats):\n",
        "    if i > starting_beat:\n",
        "      # Get slice\n",
        "      s_time = beat+timetravel\n",
        "      e_time = anal_duration-a\n",
        "      s_sample = librosa.time_to_samples(s_time, sr=sr)\n",
        "      e_sample = librosa.time_to_samples(s_time+e_time, sr=sr)\n",
        "      beat_timing = timing_track[s_sample:e_sample]\n",
        "\n",
        "      # Nudge\n",
        "      nudge_peak = get_tail_peaks(beat_timing, True)\n",
        "      if nudge_peak > 0:\n",
        "        ns_time = s_time-(anal_duration-anal_duration*nudge_peak)-a\n",
        "        ns_sample = librosa.time_to_samples(ns_time, sr=sr)\n",
        "      else:\n",
        "        ns_time = s_time\n",
        "        ns_sample = s_sample\n",
        "      ns_sample = librosa.time_to_samples(ns_time-timetravel, sr=sr)\n",
        "      ne_sample = librosa.time_to_samples(ns_time+(real_duration-a), sr=sr)\n",
        "\n",
        "      # Return start:end of each beat in either 'samples' or in 'seconds'\n",
        "      if return_type == 'samples':\n",
        "        beat_positions.append([ns_sample, ne_sample])\n",
        "      else:\n",
        "        beat_positions.append([ns_time, ns_time+(real_duration-a)])\n",
        "  return beat_positions\n",
        "\n",
        "def time_stretch_audio(audio, to_length, sr=global_sr):\n",
        "  dur = librosa.get_duration(audio, sr=sr)\n",
        "  #librosa.effects.time_stretch(y, dur/to_length)\n",
        "  return np.array([librosa.effects.time_stretch(channel, dur/to_length) for channel in split_channels(audio)])\n",
        "  \n",
        "def process_beat(audio, to_length, fx=[], sr=global_sr):\n",
        "  stretched = time_stretch_audio(audio, to_length)\n",
        "  fxd = fade_audio(apply_fx(stretched, to_length, fx))\n",
        "  return fxd\n",
        "\n",
        "def get_mode(lst):\n",
        "  d = {}\n",
        "  for a in lst:\n",
        "    if not a in d:\n",
        "      d[a]=1\n",
        "    else:\n",
        "      d[a]+=1\n",
        "  return [k for k,v in d.items() if v==max(d.values())]\n",
        "\n",
        "def convert(file_list, output_dir, sr=global_sr):\n",
        "  for i, audiofile in enumerate(file_list):\n",
        "    #print(path_leaf(audiofile), '...', end=' ')\n",
        "    output = output_dir+slug(path_leaf(basename(audiofile)))+'.wav'\n",
        "    filter = \"pan=stereo|c0=c0|c1=c0\"\n",
        "    if reverse == True:\n",
        "      filter = filter+\", areverse\"\n",
        "    if normalize == True:\n",
        "      filter = filter+\", dynaudnorm=p=1/sqrt(2):m=100:s=12:g=15\"\n",
        "    !ffmpeg {ffmpeg_q} -y -i \"{audiofile}\" -c:a pcm_s16le -ar {sr} -ac 2 -af \"{filter}\" \"{output}\"\n",
        "    #print('Done.')\n",
        "\n",
        "def clip_sources(file_list, output_dir, duration, slice_duration, sr=global_sr):\n",
        "  for i, audiofile in enumerate(file_list):\n",
        "    #print('process', audiofile)\n",
        "    #print('clip to', duration)\n",
        "    audio_data, sr = librosa.load(audiofile, sr=sr, mono=False)\n",
        "    a_duration = librosa.get_duration(audio_data, sr=sr)\n",
        "    if a_duration > slice_duration*2:\n",
        "      a_duration = a_duration/4 * random.randrange(2, 3)\n",
        "    start = librosa.time_to_samples(a_duration, sr=sr)\n",
        "    end = librosa.time_to_samples(a_duration+duration+sr, sr=sr)\n",
        "    output = output_dir+path_leaf(audiofile)\n",
        "    save(audio_data[:, start:end], output)\n",
        "    audio_data = None\n",
        "\n",
        "def get_duration(dir, sr=global_sr):\n",
        "  files = list_audio(dir)\n",
        "  duration = 0\n",
        "  for file in files:\n",
        "    duration += librosa.get_duration(filename=file, sr=sr)\n",
        "  return duration\n",
        "\n",
        "def slice_to_frames(audio_data, slice_duration, fade_in=global_fade, fade_out=global_fade, fx=[], sr=global_sr):\n",
        "  #print('slice to frames, slice length', slice)\n",
        "  a_duration = librosa.get_duration(audio_data, sr=sr)\n",
        "  # print('a_duration', a_duration)\n",
        "  clips = math.ceil(a_duration/slice_duration)\n",
        "  # print('clips', clips)\n",
        "  frames = []\n",
        "  #print('total clips:', clips)\n",
        "  # print('slice to', clips, end='')\n",
        "  #print('fx in slice_to_frames', fx)\n",
        "  for i in range(clips-1):\n",
        "    #print('clip#', i)\n",
        "    if i > 0 and i < clips:\n",
        "      start = i*slice_duration\n",
        "      #print('slice_to_frame clip_audio loop')\n",
        "      audio_clip = clip_audio(audio_data, start, slice_duration, fx)\n",
        "      frames.append( audio_clip ) #fade_audio(audio_clip, fade_in, fade_out) )\n",
        "      #print('.', end='')\n",
        "  show_mem()\n",
        "  # print('done.')\n",
        "  return frames\n",
        "\n",
        "def apply_fx(audio_data, duration, fx=[]):\n",
        "  # tremolo\n",
        "  #print('fx in apply_fx', fx)\n",
        "  if fx[0] == True:\n",
        "    xtremolo = duration/2\n",
        "    #print('duration', duration)\n",
        "    #print('apply tremolo', xtremolo)\n",
        "    audio_data = fade_audio(audio_data, xtremolo, xtremolo)\n",
        "  #release\n",
        "  elif fx[1] > 0:\n",
        "    xrelease = fx[1]/100*duration\n",
        "    audio_data = fade_audio(audio_data, global_fade, xrelease)\n",
        "  # autotune\n",
        "  if fx[2] != \"None\":\n",
        "    t = math.ceil(10*duration)\n",
        "    if t < 2:\n",
        "      t = 3\n",
        "    audio_data = autotune_audio(audio_data, note=fx[2], t=t)\n",
        "    #audio_data = fade_audio(tuned)\n",
        "  #pitch\n",
        "  elif fx[3] != 0:\n",
        "    #audio_data = fade_audio(pitch(audio_data, fx[3]))\n",
        "    audio_data = pitch(audio_data, fx[3])\n",
        "  if fx[4] == True:\n",
        "    xfade = duration/3\n",
        "    audio_data = fade_audio(audio_data, xfade, xfade)\n",
        "  return audio_data\n",
        "\n",
        "def clip_audio(audio_data, start, duration, fx=[], oneshots=False, sr=global_sr):\n",
        "  global global_fade\n",
        "  xstart = librosa.time_to_samples(start, sr=sr)\n",
        "  xduration = librosa.time_to_samples(start+duration, sr=sr)\n",
        "  #print('clip audio to duration', duration)\n",
        "  #audio_data = fade_audio(audio_data[:, xstart:xduration]) \n",
        "  audio_data = audio_data[:, xstart:xduration]\n",
        "  if len(fx) > 0:\n",
        "    audio_data = apply_fx(audio_data, duration, fx)\n",
        "  if fx[0] == False and fx[1] == 0:\n",
        "    audio_data = fade_audio(audio_data) \n",
        "  \n",
        "  show_mem()\n",
        "  #print(audio_data.shape)\n",
        "  return audio_data\n",
        "\n",
        "def fade_audio(audio_data, fade_in=global_fade, fade_out=global_fade, sr=global_sr):\n",
        "  a_duration = librosa.get_duration(audio_data, sr=sr)\n",
        "  #print('in ', fade_in )\n",
        "  #print('out', fade_out )\n",
        "  #waveform(audio_data)\n",
        "  if fade_in > 0:\n",
        "    fade_in_to = librosa.time_to_samples(fade_in, sr=sr)\n",
        "    in_y = audio_data[:, 0:fade_in_to]\n",
        "    fade_ins = []\n",
        "    for channel in in_y:\n",
        "      fade = [ i/len(channel)*smp for i, smp in enumerate(channel) ]\n",
        "      fade_ins.append(fade)\n",
        "    fade_ins = np.array(fade_ins)\n",
        "    tail_start = fade_in_to+1  \n",
        "    tail = audio_data[:, tail_start:]\n",
        "    audio_data = np.concatenate([fade_ins, tail], axis=1)\n",
        "    #waveform(audio_data)\n",
        "  if fade_out > 0:\n",
        "    fade_out_start = librosa.time_to_samples(a_duration-fade_out, sr=sr)\n",
        "    out_y = audio_data[:, fade_out_start:]\n",
        "    fade_outs = []\n",
        "    for channel in out_y:\n",
        "      fade = [ smp-(i/len(channel)*smp) for i, smp in enumerate(channel) ]\n",
        "      fade_outs.append(fade)\n",
        "    fade_outs = np.array(fade_outs)\n",
        "    head_start = fade_out_start-1\n",
        "    head = audio_data[:, :head_start]\n",
        "    audio_data = np.concatenate([head, fade_outs], axis=1)\n",
        "    #waveform(audio_data)\n",
        "  return audio_data\n",
        "\n",
        "def split_channels(audio_data):\n",
        "  return audio_data[0], audio_data[1]\n",
        "\n",
        "def merge_channels(left_data, right_data):\n",
        "  return np.array([left_data, right_data])\n",
        "\n",
        "def detect_pitch(audio_data, t, sr=global_sr):\n",
        "  pitches, magnitudes = librosa.core.piptrack(y=audio_data, sr=sr, fmin=50, fmax=900)\n",
        "  # print(pitches)\n",
        "  index = magnitudes[:, t].argmax()\n",
        "  pitch = pitches[index, t]\n",
        "  # print('detect_pitch pitch:', pitch)\n",
        "  return pitch\n",
        "\n",
        "def pitch(audio_data, semitones, sr=global_sr):\n",
        "  pitched = np.array([librosa.effects.pitch_shift(channel, sr=sr, n_steps=semitones, bins_per_octave=12) for channel in split_channels(audio_data)])\n",
        "  audio_data = None\n",
        "  return pitched\n",
        "\n",
        "def autotune_audio(audio_data, note='C', sr=global_sr, t=10):\n",
        "  target_note = librosa.note_to_midi(note)\n",
        "  # print('note', note)\n",
        "  mono_audio = librosa.to_mono(audio_data)\n",
        "  pitch = detect_pitch(mono_audio, t, sr=sr)\n",
        "  # print('pitch hz', pitch)\n",
        "  source_note = round(librosa.hz_to_midi(pitch))\n",
        "  # print('hz_to_midi', midi)\n",
        "  if source_note > 0:\n",
        "    diff = round(target_note-source_note)\n",
        "    oct = 12 if diff > 0 else -12\n",
        "    octs = math.floor(diff/oct)\n",
        "    if octs > 0:\n",
        "      diff = diff-octs*oct\n",
        "    elif octs < 0:\n",
        "      diff = diff+octs*oct\n",
        "\n",
        "    if diff < -6:\n",
        "      if octs < 0:\n",
        "        diff = octs*oct-diff\n",
        "      else:\n",
        "        diff = oct-diff\n",
        "    elif diff > 6:\n",
        "      if octs > 0:\n",
        "        diff = octs*oct+diff\n",
        "      else:\n",
        "        diff = oct-diff \n",
        "    tuned = np.array([librosa.effects.pitch_shift(channel, sr=sr, n_steps=diff, bins_per_octave=12) for channel in split_channels(audio_data)])\n",
        "  else:\n",
        "    tuned = audio_data\n",
        "  mono_audio = None\n",
        "  audio_data = None\n",
        "  return tuned\n",
        "\n",
        "def generate_silence(duration, sr=global_sr):\n",
        "  content = [0]*librosa.time_to_samples(duration, sr=sr)\n",
        "  silence = np.array([content, content], dtype=np.float32)\n",
        "  return silence\n",
        "\n",
        "#--- saving + other -------------------------------------------------------------------------\n",
        "\n",
        "def save(audio_data, save_as='frank', sr=global_sr):\n",
        "  if save_as=='frank':\n",
        "    global bpm\n",
        "    timestamp = datetime.datetime.today().strftime('%Y%m%d-%H%M%S')\n",
        "    save_as = save_as+'_'+rnd_str(4)+'_'+timestamp+'__'+bpm+'bpm.wav'\n",
        "  soundfile.write(save_as, audio_data.T, sr)\n",
        "\n",
        "def test_audio(audio_data):\n",
        "  global dir_tmp\n",
        "  if not isinstance(audio_data, (np.ndarray, np.generic)):\n",
        "    global global_sr\n",
        "    audio_data, sr = librosa.load(audio_data, mono=False, sr=global_sr)\n",
        "  out = dir_tmp+'test_'+rnd_str(8)\n",
        "  save(audio_data, out+'.wav')\n",
        "  !ffmpeg {ffmpeg_q} -i {out}.wav {mp3_192} {out}.mp3\n",
        "  audio_player(out+'.mp3')\n",
        "\n",
        "def show_mem():\n",
        "  global extra_verbose_performance\n",
        "  if extra_verbose_performance is True:\n",
        "    print('mem:', psutil.virtual_memory().percent, '/', psutil.virtual_memory().available * 100 / psutil.virtual_memory().total)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "output.clear()\n",
        "op(c.ok, 'Setup finished.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzm2l_dCO_mB",
        "cellView": "form"
      },
      "source": [
        "#@title #Butcher\n",
        "\n",
        "#@markdown ##Audio source material\n",
        "input_dir = \"sloppybutcher\" #@param {type:\"string\"}\n",
        "#handle_silence = \"None\" #@param [\"None\", \"Trim_beginning_and_end\", \"Remove_everywhere\"]\n",
        "handle_silence = \"None\"\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown ##Saving\n",
        "#@markdown <small>Checking `save_to_drive` will save every generated output file to your Drive. Uncheck if you just want to play around and listen to the previews before getting serious. Mounting Drive is still required for source audio.</small>\n",
        "save_to_drive = False #@param {type:\"boolean\"}\n",
        "output_dir = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown ##Basics\n",
        "bpm = 120 #@param {type:\"slider\", min:60, max:200, step:1}\n",
        "slices_per_beat = 2 #@param {type:\"slider\", min:1, max:4}\n",
        "vol = 95 #@param {type:\"slider\", min:1, max:100}\n",
        "target_duration = 15 #@param {type:\"slider\", step:5, min:10, max:120}\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown ##Fancy\n",
        "slice_to_beats = False #@param {type:\"boolean\"}\n",
        "pitch_semitone = 0 #@param {type:\"slider\", min:-24, max:24, step:1}\n",
        "autotune = \"None\" #@param [\"None\", \"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
        "reverb = 25 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "reverse = False #@param {type:\"boolean\"}\n",
        "normalize = False #@param {type:\"boolean\"}\n",
        "dry_distort = False #@param {type:\"boolean\"}\n",
        "release = 99 #@param {type:\"slider\", min:0, max:99}\n",
        "#@markdown <small>`silence_amount` is the probability of any given beat being silence instead.</small>\n",
        "silence_amount = 0 #@param {type:\"slider\", min:0, max:99}\n",
        "#@markdown <small>`tremolo` will override `release`.</small>\n",
        "tremolo = False #@param {type:\"boolean\"}\n",
        "#@markdown <small>`crossfade` will override `release` and `tremolo`.</small>\n",
        "crossfade = False #@param {type:\"boolean\"}\n",
        "\n",
        "op(c.title, 'Starting...\\n')\n",
        "\n",
        "# Dirs\n",
        "if hosted_runtime == True:\n",
        "  input_dir = drive_root+fix_path(input_dir, True)\n",
        "else:\n",
        "  output_dir = project_home+\"/Generated-output-WAVs/\"\n",
        "  !mkdir {output_dir}\n",
        "  save_to_drive = True\n",
        "\n",
        "# Clone material for Butcher\n",
        "material = dir_tmp+'source-material/'\n",
        "converted = dir_tmp+'converted/'\n",
        "converted_clipped = dir_tmp+'converted-clipped/'\n",
        "dir_slices = dir_tmp+'slices/'\n",
        "dir_kicks = dir_slices+'perc-kicks/'\n",
        "dir_snares = dir_slices+'perc-snares/'\n",
        "dir_other = dir_slices+'perc-other/'\n",
        "\n",
        "dirs = [material, converted, converted_clipped, dir_slices]\n",
        "if output_dir != '':\n",
        "  dirs.append(output_dir);\n",
        "create_dirs(dirs)\n",
        "\n",
        "source_files = list_audio(input_dir)\n",
        "if source_files != last_source_files:\n",
        "  if len(list_audio(material)) > 0:\n",
        "    !rm {material}*\n",
        "  for source_file in source_files:\n",
        "    shutil.copy(source_file, material)\n",
        "#copy_tree(input_dir, material)\n",
        "\n",
        "if crossfade == True:\n",
        "  slices_per_beat = slices_per_beat / 2\n",
        "  approx_duration = approx_duration * 2\n",
        "  trackDuration = approx_duration\n",
        "\n",
        "# Adjustments\n",
        "fade = 0.003\n",
        "fade_in = fade\n",
        "fade_out = fade\n",
        "minute = 60\n",
        "global_bpm = bpm\n",
        "vol = vol/100\n",
        "reverb_amount = reverb\n",
        "reverb_damping = 100-reverb\n",
        "pitch = pitch_semitone*100\n",
        "approx_duration = target_duration\n",
        "trackData = [None]\n",
        "oneshots = False\n",
        "silence_identifier = 'corpus_silentium'\n",
        "prefix = \"frankenstein\"\n",
        "sr = 44100\n",
        "recycle_material = False\n",
        "\n",
        "if autotune != \"None\":\n",
        "  autotune = autotune+str(3)\n",
        "  \n",
        "sox_q = '-q'\n",
        "\n",
        "global_sr = sr\n",
        "global_fade = fade\n",
        "\n",
        "# Conflict warnings\n",
        "def conflictWarn(reset=False):\n",
        "  global crossfade, tremolo, release, autotune, pitch_semitone\n",
        "  msgtype = c.warn\n",
        "  errors = False\n",
        "  if crossfade == True and release > 0:\n",
        "    op(msgtype, '\\nWARN! Crossfade cancels release, which you have set to '+str(release)+'.')\n",
        "    errors = True\n",
        "    if reset == True:\n",
        "      release = 0\n",
        "  if crossfade == True and tremolo == True:\n",
        "    op(msgtype, '\\nWARN! Crossfade cancels tremolo.')\n",
        "    errors = True\n",
        "    if reset == True:\n",
        "      tremolo = False\n",
        "  if crossfade == False and tremolo == True and release > 0:\n",
        "    op(msgtype, '\\nWARN! Tremolo cancels release, which you have set to '+str(release)+'.')\n",
        "    errors = True\n",
        "    if reset == True:\n",
        "      release = 0\n",
        "  if autotune != \"None\" and pitch_semitone != 0:\n",
        "    op(msgtype, '\\nWARN! Autotune cancels pitch_semitone, which you have set to '+pitch_semitone+'.')\n",
        "    errors = True\n",
        "    if reset == True:\n",
        "      pitch_semitone = 0\n",
        "  if errors == False:\n",
        "    if reset == True:\n",
        "      print('Settings................................ OK')\n",
        "    else:\n",
        "      op(c.ok, 'Seems fine.')\n",
        "\n",
        "#conflictWarn()\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------\n",
        "# --- Beat slicing prerequisities\n",
        "# ----------------------------------------------------------------------------------\n",
        "if (not 'beatslice_setup_done' in globals() or force_setup == True) and slice_to_beats == True:\n",
        "  print('\\nSetup required Neural Networks...')\n",
        "  !pip -q install {pip_packages_beatslice}\n",
        "  !gsutil -q -m cp -R gs://neural-research/olaviinha/spleeter-configs/custom-4stems-22kHz-z.json /content/cfg.json\n",
        "  import sys, warnings\n",
        "  import essentia\n",
        "  import essentia.standard\n",
        "  import essentia.streaming\n",
        "  from statistics import mode\n",
        "  from essentia import Pool, array\n",
        "  from essentia.standard import *\n",
        "  from spleeter.separator import Separator\n",
        "  from spleeter.audio.adapter import get_default_audio_adapter\n",
        "  beatslice_setup_done = True\n",
        "\n",
        "  print('Done.\\n')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------\n",
        "# --- Basics\n",
        "# ----------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "bpm = global_bpm\n",
        "total_slices = math.ceil((bpm/minute)*slices_per_beat*approx_duration)\n",
        "trackDuration = approx_duration\n",
        "pretty_trackDuration = str(datetime.timedelta(seconds=trackDuration))\n",
        "slice_duration = minute/bpm/slices_per_beat\n",
        "\n",
        "beat = minute/bpm\n",
        "materialDuration = get_duration(material)\n",
        "pretty_materialDuration = str(datetime.timedelta(seconds=materialDuration))\n",
        "\n",
        "sources = glob(material+\"*\")\n",
        "sources.sort()\n",
        "per_source_length = math.ceil(trackDuration/len(sources) + 1)\n",
        "\n",
        "if per_source_length < slice_duration:\n",
        "  per_source_length = slice_duration\n",
        "slices_per_source = math.ceil(total_slices / len(sources))\n",
        "\n",
        "if show_info == True:\n",
        "  op(c.title, '\\n> Information')\n",
        "  print('Input:..................................', input_dir)\n",
        "  print('Source files:...........................', len(sources))\n",
        "  print('Duration:...............................', pretty_materialDuration)\n",
        "\n",
        "  if trackDuration > materialDuration:\n",
        "    op(c.fail, 'Track target duration:.................. '+pretty_trackDuration)\n",
        "  else:\n",
        "    print('Track target duration:..................', pretty_trackDuration)\n",
        "\n",
        "  print('Slices required:........................', total_slices)\n",
        "\n",
        "  print('Required per source:....................', str(datetime.timedelta(seconds=per_source_length)))\n",
        "  print('Slices per source:......................', slices_per_source)\n",
        "  #print(slice * slices_per_source)\n",
        "  print('BPM:....................................', bpm)\n",
        "  print('Slices per beat.........................', slices_per_beat)\n",
        "  print('Beat interval:..........................', beat)\n",
        "  print('Slice duration:.........................', slice_duration)\n",
        "\n",
        "  if slice_to_beats == True:\n",
        "    print('Slice to beats:.........................', slice_to_beats)\n",
        "\n",
        "#print(f\"{bcolors.WARNING}Warning: No active frommets remain. Continue?{bcolors.ENDC}\")\n",
        "\n",
        "conflictWarn(reset=True)\n",
        "\n",
        "if trackDuration > materialDuration:\n",
        "  recycle_times = math.ceil(trackDuration/materialDuration)\n",
        "  op(c.fail, '\\nWARN! Not enough material for target duration. Material will be recycled '+str(recycle_times)+' times to meet target duration.')\n",
        "  recycle_material = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------\n",
        "# --- Butcher\n",
        "# ----------------------------------------------------------------------------------\n",
        "\n",
        "mode = 'rosa'\n",
        "\n",
        "force_conversion = True\n",
        "force_rough_chops = True\n",
        "force_silence_generation = True\n",
        "force_slice = True\n",
        "\n",
        "op(c.title, '\\nIn Progress:')\n",
        "\n",
        "def prg(task):\n",
        "  print('\\r', task, end=' ')\n",
        "\n",
        "# Convert\n",
        "if sources != last_conversion or last_reverse != reverse or force_conversion == True:\n",
        "  prg('Convert...')\n",
        "  !rm {converted}*\n",
        "  convert(sources, converted)\n",
        "  converted_sources = list_audio(converted)\n",
        "  process_dir = converted\n",
        "  last_conversion = sources\n",
        "  last_reverse = reverse\n",
        "\n",
        "  # Rough cut\n",
        "  if (((per_source_length != last_per_source_length or trackDuration+materialDuration != last_durations) and recycle_material == False) or force_rough_chops == True) and slice_to_beats == True:\n",
        "    prg('Rough chops...')\n",
        "    !rm {converted_clipped}*\n",
        "    converted_sources = list_audio(converted)\n",
        "    converted_sources.sort()\n",
        "    clip_sources(converted_sources, converted_clipped, per_source_length, slice_duration)\n",
        "    converted_sources = list_audio(converted_clipped)\n",
        "    process_dir = converted_clipped\n",
        "    last_per_source_length = per_source_length\n",
        "    last_durations = trackDuration+materialDuration\n",
        "\n",
        "prg('Recycling...')\n",
        "if recycle_material == True:\n",
        "  converted_concat = []\n",
        "  for i in range(recycle_times):\n",
        "    converted_concat.extend(converted_sources[:])\n",
        "  converted_sources = converted_concat\n",
        "\n",
        "# Slice up\n",
        "if slices_per_beat != last_slices_per_beat or bpm != last_bpm or force_slice == True:\n",
        "  prg('Chopping...')\n",
        "  fx = [tremolo, release, autotune, pitch_semitone, crossfade]\n",
        "\n",
        "  print(fx)\n",
        "\n",
        "  sl_slices = dir_slices+str(slices_per_beat)+'/'\n",
        "  create_dirs([sl_slices])\n",
        "  #slice_time = beat/slices_per_beat\n",
        "  source_slice_list = []\n",
        "  all = []\n",
        "\n",
        "  for x, source in enumerate(converted_sources):\n",
        "    y, sr = librosa.load(source, sr=sr, mono=False)\n",
        "    show_mem()\n",
        "\n",
        "    if slice_to_beats == True:\n",
        "      prg('Slicing to beats...')\n",
        "\n",
        "      # Beat slicery\n",
        "      timing_track = separate_drums(y)\n",
        "      beats = get_beats(timing_track, sr)\n",
        "\n",
        "      # Add precision\n",
        "      decs = 2\n",
        "      precise_durations = get_differences(beats, 0)\n",
        "      compressed_durations = get_differences(beats, decs)\n",
        "      duration_range = most_frequent(compressed_durations)\n",
        "      filtered_durations = filter_durations(precise_durations, duration_range, decs)\n",
        "      xs_beat = min(filtered_durations)\n",
        "      m_beat = get_mode(filtered_durations)\n",
        "      xl_beat = max(filtered_durations)+0.02\n",
        "      nudged_beats = nudge(beats, timing_track, xl_beat, xs_beat, 0, 'samples')\n",
        "\n",
        "      # Timestretch\n",
        "      prg('Time-stretching...')\n",
        "      for i, beat in enumerate(nudged_beats):\n",
        "        stretched_beat = process_beat(y[:, beat[0]:beat[1]], slice_duration, fx) \n",
        "        all.append(stretched_beat)\n",
        "\n",
        "    else:\n",
        "      source_slice_list = slice_to_frames(y, slice_duration, fx=fx)\n",
        "      for i, source_slice in enumerate(source_slice_list):\n",
        "        if mode == 'rosa':\n",
        "          all.append(source_slice)\n",
        "        else:\n",
        "          save(source_slice, sl_slices+str(x).zfill(4)+'-'+str(i).zfill(4)+'.wav')\n",
        "\n",
        "    source_slice_list = []\n",
        "    y = None\n",
        "    show_mem()\n",
        "\n",
        "  if mode == 'rosa':\n",
        "    random.shuffle(all)\n",
        "    chop_list = all\n",
        "  else:\n",
        "    chop_list = glob(sl_slices+'*.wav')\n",
        "  all = []\n",
        "  last_slices_per_beat = slices_per_beat\n",
        "  last_bpm = bpm\n",
        "\n",
        "# Concatenate\n",
        "prg('Concatenating...')\n",
        "input_list = []\n",
        "\n",
        "y = 0\n",
        "if crossfade == True:\n",
        "  input_list1 = []\n",
        "  input_list2 = []\n",
        "  input_list2.append(generate_silence(slice_duration/2))\n",
        "  for x in range(0, math.ceil(total_slices/2)):\n",
        "    if odds(silence_amount/100):\n",
        "      add = generate_silence(slice_duration)\n",
        "    else:\n",
        "      add = chop_list[y]\n",
        "    y += 1\n",
        "    input_list1.append(add)\n",
        "  for x in range(math.ceil(total_slices/2), total_slices):\n",
        "    if odds(silence_amount/100):\n",
        "      add = generate_silence(slice_duration)\n",
        "    else:\n",
        "      add = chop_list[y]\n",
        "    y += 1\n",
        "    input_list2.append(add)\n",
        "  chop_list = []\n",
        "\n",
        "  if reverb > 0:\n",
        "    input_list1.append(generate_silence(5))\n",
        "    input_list2.append(generate_silence(5))\n",
        "\n",
        "  input_list1.append(generate_silence(slice_duration/2))\n",
        "  concat_audio1 = np.concatenate(input_list1, axis=1)\n",
        "  concat_audio2 = np.concatenate(input_list2, axis=1)\n",
        "  \n",
        "  if concat_audio1.shape[1] < concat_audio2.shape[1]:\n",
        "    slen = concat_audio2.shape[1]-concat_audio1.shape[1]\n",
        "    tail = np.array([[0]*slen, [0]*slen], dtype=np.float32)\n",
        "    concat_audio1 = np.concatenate((concat_audio1, tail), axis=1)\n",
        "  elif concat_audio1.shape[1] > concat_audio2.shape[1]:\n",
        "    slen = concat_audio1.shape[1]-concat_audio2.shape[1]\n",
        "    tail = np.array([[0]*slen, [0]*slen], dtype=np.float32)\n",
        "    concat_audio2 = np.concatenate((concat_audio2, tail), axis=1)\n",
        "\n",
        "  concat_audio = np.add.reduce([concat_audio1, concat_audio2])\n",
        "  \n",
        "else:\n",
        "  for x in range(total_slices):\n",
        "    if odds(silence_amount/100):\n",
        "      add = generate_silence(slice_duration)\n",
        "    else:\n",
        "      add = chop_list[y]\n",
        "    y += 1\n",
        "    input_list.append(add)\n",
        "  chop_list = []\n",
        "\n",
        "  if reverb > 0:\n",
        "    input_list.append(generate_silence(5))\n",
        "\n",
        "  concat_audio = np.concatenate(input_list, axis=1)\n",
        "\n",
        "prg('Post-processing...')\n",
        "\n",
        "timestamp = datetime.datetime.today().strftime('%Y%m%d-%H%M%S')\n",
        "post_as = rnd_str(4)+'_'+timestamp+'__'+str(bpm)+'bpm.wav'\n",
        "save_as = 'frankenstein_'+post_as\n",
        "\n",
        "\n",
        "if reverb > 0:\n",
        "  save(concat_audio, dir_tmp+post_as)\n",
        "  prg('Adding reverb...')\n",
        "  !sox -v {vol} \"{dir_tmp}{post_as}\" -r 48000 -c 2 -b 24 \"{dir_tmp}{save_as}\" reverb {reverb_amount} {reverb_damping} 100 100 0 0\n",
        "else:\n",
        "  save(concat_audio, dir_tmp+save_as)\n",
        "\n",
        "op(c.ok, 'OK.\\n ')\n",
        "\n",
        "if save_to_drive == True:\n",
        "  !cp \"{dir_tmp}{save_as}\" \"{output_dir}{save_as}\"\n",
        "\n",
        "waveform(concat_audio)\n",
        "print('\\n')\n",
        "test_audio(dir_tmp+save_as)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}